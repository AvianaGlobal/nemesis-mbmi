% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sql.R
\name{copy_file_to_sql}
\alias{copy_file_to_sql}
\title{Copy file to SQL table}
\usage{
copy_file_to_sql(in_file, out_conn, out_table, initial_rows = 10000L,
  batch_bytes = getOption("ffbatchbytes"), ...)
}
\arguments{
\item{\code{in_file}}{input path or connection}

\item{\code{out_conn}}{database to copy to (DBI connection)}

\item{\code{out_table}}{name of table to copy to}

\item{\code{initial_rows}}{number of lines to read in first batch}

\item{\code{batch_bytes}}{size of subsequent batches in bytes}

\item{\code{...}}{arguments to pass to \code{fread} (see details)}
}
\description{
Copy a flat file to a table in a SQL database.
}
\details{
The copy is performed by reading the data from the input file to
memory, then pushing it from memory to the output DB. To avoid excessive
memory usage, the file is read in batches.

Technically, this functionality is already built into \code{dbWriteTable}.
However, that implementation uses the DB-specific import function, which
can be unreliable. For example, SQLite cannot handle column separators
inside quotes. For consistency and reliability, we use \code{fread} from the
\code{data.table} package to parse the input file.
}
